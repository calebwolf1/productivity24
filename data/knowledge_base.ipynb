{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Knowledge Base \n",
    "Using a RAG pipeline and evaluating with LlamaIndex for question/answer pairs in e-commerce customer support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The nest_asyncio module enables the nesting of asynchronous functions within an already running async loop.\n",
    "# This is necessary because Jupyter notebooks inherently operate in an asynchronous loop.\n",
    "# By applying nest_asyncio, we can run additional async functions within this existing loop without conflicts.\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "from llama_index.core.evaluation import generate_question_context_pairs\n",
    "from llama_index.core import VectorStoreIndex, ServiceContext\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.core.evaluation import RetrieverEvaluator\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.readers.json import JSONReader\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = JSONReader(is_jsonl = True).load_data(\"converted_conversations.jsonl\")\n",
    "\n",
    "# Define an LLM\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Build index with a chunk_size of 512\n",
    "node_parser = SimpleNodeParser.from_defaults(chunk_size=512)\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "vector_index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Your order is currently in transit and should arrive within the next two business days. If you do not receive it by then, it is recommended to reach out to investigate further.', source_nodes=[NodeWithScore(node=TextNode(id_='2cb24443-50bb-4df8-8c33-3033bc3252bc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='40fe1259-6e76-4358-9b3f-0610069b7e02', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='6f220b567b742bd968381d3ea7f9c6786bfc92b7f4bd4da87973b9a4af773d17'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c968a300-344a-459b-94ec-d7cc5644da85', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6ac01b28e1596a6c89bf24c116ce73bbda3efd25539567de219849fea394fe4d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='32a7f41d-8be1-42b5-a126-fe605cc22d4a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5926ece82fb4ef95e09e94e5b62f4ed091d678fcf9df389a79ba8601dd1d5346')}, text='However, we do offer different shipping options, including expedited shipping, which is faster but comes with an additional charge. Would you like me to check if that\\'s available for your order?\"\\n\"role\": \"user\",\\n\"content\": \"No, I don\\'t want to pay extra. I just want to know when I can expect my order to arrive.\"\\n\"role\": \"assistant\",\\n\"content\": \"I completely understand. Let me check the status of your order. Could you please hold for a moment?\"\\n\"role\": \"user\",\\n\"content\": \"Okay, I\\'ll hold.\"\\n\"role\": \"assistant\",\\n\"content\": \"Thank you for waiting. I see that your order is currently in transit and should arrive within the next two business days. If you don\\'t receive it by then, please let us know, and we\\'ll investigate further.\"\\n\"role\": \"user\",\\n\"content\": \"Okay, I\\'ll wait for two more days. But I don\\'t think I should have to pay for shipping if it takes so long to arrive.\"\\n\"role\": \"assistant\",\\n\"content\": \"I understand your concern, and I apologize for the delay. We always strive to provide the best possible service to our customers. If you have any other questions or concerns, please don\\'t hesitate to contact us.\"\\n\"role\": \"user\",\\n\"content\": \"Okay, thank you for your help.\"\\n\"role\": \"assistant\",\\n\"content\": \"You\\'re welcome. Have a great day!\"\\n\"role\": \"user\",\\n\"content\": \"You too. Goodbye!\"\\n\"role\": \"assistant\",\\n\"content\": \"Goodbye!\"', start_char_idx=1232, end_char_idx=2576, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8355510785202788), NodeWithScore(node=TextNode(id_='7da32c69-adcc-4fe3-a5a7-d7ecef0a924b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='b32d0aa2-73f8-4bd1-b71f-c5b59fbb42cf', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='71c0f1bdd08566ca6436a9d23928d2357d43489474ad8fb7955b0320706c583a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='838f5b96-fce2-47f9-a80f-d02258765ac4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3d152751650b898f04a80c8040691c302a11eaaee1feabd342a47df503d2bc21'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='feb79108-67e5-4947-a255-cc5904382072', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='70a30300fe2ca2d4700f04d9e223b4c79eb9a90da9b15d000c581fff67be0f9d')}, text='I\\'ll also send you an email with the updated status of your order.\"\\n\"role\": \"user\",\\n\"content\": \"Okay, thank you. But why is it taking so long? It\\'s been two days now.\"\\n\"role\": \"assistant\",\\n\"content\": \"I\\'m sorry for the delay. Sometimes, due to unforeseen circumstances, the shipment may get delayed. But I assure you that we are doing our best to get it delivered to you as soon as possible.\"\\n\"role\": \"user\",\\n\"content\": \"Okay, I hope so.\"\\n\"role\": \"assistant\",\\n\"content\": \"Is there anything else I can assist you with?\"\\n\"role\": \"user\",\\n\"content\": \"No, that\\'s all for now.\"\\n\"role\": \"assistant\",\\n\"content\": \"Okay, please keep an eye on your email for updates on your order. If you have any further concerns, please don\\'t hesitate to contact us. Thank you for choosing BrownBox.\"\\n\"role\": \"user\",\\n\"content\": \"Thank you.\"', start_char_idx=1187, end_char_idx=2002, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8296518165884488)], metadata={'2cb24443-50bb-4df8-8c33-3033bc3252bc': {}, '7da32c69-adcc-4fe3-a5a7-d7ecef0a924b': {}})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_vector = query_engine.query(\"I have been waiting for my order for a long time. When will it get here?\")\n",
    "response_vector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
