{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restructuring Data E-Commerce Customer Support Conversations\n",
    "\n",
    "conversation column is back-and-forth between agent and customer\n",
    "\n",
    "source: https://huggingface.co/datasets/NebulaByte/E-Commerce_Customer_Support_Conversations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue_area</th>\n",
       "      <th>issue_category</th>\n",
       "      <th>issue_sub_category</th>\n",
       "      <th>issue_category_sub_category</th>\n",
       "      <th>customer_sentiment</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_sub_category</th>\n",
       "      <th>issue_complexity</th>\n",
       "      <th>agent_experience_level</th>\n",
       "      <th>agent_experience_level_desc</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Login and Account</td>\n",
       "      <td>Mobile Number and Email Verification</td>\n",
       "      <td>Verification requirement for mobile number or ...</td>\n",
       "      <td>Mobile Number and Email Verification -&gt; Verifi...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>Oven Toaster Grills (OTG)</td>\n",
       "      <td>medium</td>\n",
       "      <td>junior</td>\n",
       "      <td>handles customer inquiries independently, poss...</td>\n",
       "      <td>Agent: Thank you for calling BrownBox Customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cancellations and returns</td>\n",
       "      <td>Pickup and Shipping</td>\n",
       "      <td>Reasons for being asked to ship the item</td>\n",
       "      <td>Pickup and Shipping -&gt; Reasons for being asked...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Computer Monitor</td>\n",
       "      <td>less</td>\n",
       "      <td>junior</td>\n",
       "      <td>handles customer inquiries independently, poss...</td>\n",
       "      <td>Agent: Thank you for calling BrownBox customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cancellations and returns</td>\n",
       "      <td>Replacement and Return Process</td>\n",
       "      <td>Inability to click the 'Cancel' button</td>\n",
       "      <td>Replacement and Return Process -&gt; Inability to...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>Juicer/Mixer/Grinder</td>\n",
       "      <td>medium</td>\n",
       "      <td>experienced</td>\n",
       "      <td>confidently handles complex customer issues, e...</td>\n",
       "      <td>Agent: Thank you for calling BrownBox Customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Login and Account</td>\n",
       "      <td>Login Issues and Error Messages</td>\n",
       "      <td>Error message regarding exceeded attempts to e...</td>\n",
       "      <td>Login Issues and Error Messages -&gt; Error messa...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>Water Purifier</td>\n",
       "      <td>less</td>\n",
       "      <td>inexperienced</td>\n",
       "      <td>may struggle with ambiguous queries, rely on c...</td>\n",
       "      <td>Customer: Hi, I am facing an issue while loggi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Order</td>\n",
       "      <td>Order Delivery Issues</td>\n",
       "      <td>Delivery not attempted again</td>\n",
       "      <td>Order Delivery Issues -&gt; Delivery not attempte...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Bp Monitor</td>\n",
       "      <td>medium</td>\n",
       "      <td>experienced</td>\n",
       "      <td>confidently handles complex customer issues, e...</td>\n",
       "      <td>Agent: Thank you for contacting BrownBox custo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  issue_area                        issue_category  \\\n",
       "0          Login and Account  Mobile Number and Email Verification   \n",
       "1  Cancellations and returns                   Pickup and Shipping   \n",
       "2  Cancellations and returns        Replacement and Return Process   \n",
       "3          Login and Account       Login Issues and Error Messages   \n",
       "4                      Order                 Order Delivery Issues   \n",
       "\n",
       "                                  issue_sub_category  \\\n",
       "0  Verification requirement for mobile number or ...   \n",
       "1           Reasons for being asked to ship the item   \n",
       "2             Inability to click the 'Cancel' button   \n",
       "3  Error message regarding exceeded attempts to e...   \n",
       "4                       Delivery not attempted again   \n",
       "\n",
       "                         issue_category_sub_category customer_sentiment  \\\n",
       "0  Mobile Number and Email Verification -> Verifi...            neutral   \n",
       "1  Pickup and Shipping -> Reasons for being asked...            neutral   \n",
       "2  Replacement and Return Process -> Inability to...            neutral   \n",
       "3  Login Issues and Error Messages -> Error messa...            neutral   \n",
       "4  Order Delivery Issues -> Delivery not attempte...           negative   \n",
       "\n",
       "  product_category       product_sub_category issue_complexity  \\\n",
       "0       Appliances  Oven Toaster Grills (OTG)           medium   \n",
       "1      Electronics           Computer Monitor             less   \n",
       "2       Appliances       Juicer/Mixer/Grinder           medium   \n",
       "3       Appliances             Water Purifier             less   \n",
       "4      Electronics                 Bp Monitor           medium   \n",
       "\n",
       "  agent_experience_level                        agent_experience_level_desc  \\\n",
       "0                 junior  handles customer inquiries independently, poss...   \n",
       "1                 junior  handles customer inquiries independently, poss...   \n",
       "2            experienced  confidently handles complex customer issues, e...   \n",
       "3          inexperienced  may struggle with ambiguous queries, rely on c...   \n",
       "4            experienced  confidently handles complex customer issues, e...   \n",
       "\n",
       "                                        conversation  \n",
       "0  Agent: Thank you for calling BrownBox Customer...  \n",
       "1  Agent: Thank you for calling BrownBox customer...  \n",
       "2  Agent: Thank you for calling BrownBox Customer...  \n",
       "3  Customer: Hi, I am facing an issue while loggi...  \n",
       "4  Agent: Thank you for contacting BrownBox custo...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('customer_agent.json', lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No assistant :(\n",
      "No assistant :(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def reformat_conversation(conversation):\n",
    "    lines = conversation.split('\\n\\n')\n",
    "    reformatted = []\n",
    "    assistant_count = 0\n",
    "    for line in lines:\n",
    "        if line.startswith('Agent:'):\n",
    "            reformatted.append({\"role\": \"assistant\", \"content\": line.replace('Agent: ', '')})\n",
    "            assistant_count += 1\n",
    "        elif line.startswith('Customer:'):\n",
    "            reformatted.append({\"role\": \"user\", \"content\": line.replace('Customer: ', '')})\n",
    "    \n",
    "    if assistant_count > 0:\n",
    "        return reformatted\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def process_file_line_by_line(input_file_path, output_file_path):\n",
    "    reformatted_data = []\n",
    "    \n",
    "    # process each line as separate json object\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                item = json.loads(line)\n",
    "                conversation = item.get('conversation', '')\n",
    "                reformatted_conversation = reformat_conversation(conversation)\n",
    "                if reformatted_conversation is not None:\n",
    "                    system_message = {\"role\": \"system\", \"content\": \"A polite chatbot that deals with e-commerce products.\"}\n",
    "                    reformatted_conversation.insert(0, system_message)\n",
    "                    reformatted_data.append({\"messages\": reformatted_conversation})\n",
    "                else:\n",
    "                    print(\"No assistant :(\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Error decoding JSON from line:\", line)\n",
    "                continue\n",
    "    \n",
    "    # write reformatted conversations to new json file\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(reformatted_data, outfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "# specify path to input file and desired output file\n",
    "input_file_path = 'customer_agent.json'\n",
    "output_file_path = 'converted_conversations.json'\n",
    "\n",
    "# process file\n",
    "process_file_line_by_line(input_file_path, output_file_path)\n",
    "\n",
    "output_file_path\n",
    "\n",
    "f = open(output_file_path)\n",
    "data = json.load(f)\n",
    "with open(output_file_path, 'r') as f:\n",
    "    with open('converted_conversations.jsonl', 'w') as outfile:\n",
    "        for entry in data:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'invalid_request_error', 'param': None, 'code': 'exceeded_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m      9\u001b[0m file_name \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mfiles\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     10\u001b[0m   file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconverted_conversations.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     11\u001b[0m   purpose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfine-tune\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# print(getattr(file_name, 'id'))\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m create_job \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tuning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtraining_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# client.fine_tuning.jobs.list()\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# with open(conversations_path, \"rb\") as file:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#   purpose=\"fine-tune\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "File \u001b[0;32m~/Convergent/productivity24/.venv/lib/python3.12/site-packages/openai/resources/fine_tuning/jobs.py:112\u001b[0m, in \u001b[0;36mJobs.create\u001b[0;34m(self, model, training_file, hyperparameters, suffix, validation_file, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m     58\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FineTuningJob:\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    Creates a fine-tuning job which begins the process of creating a new model from\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    a given dataset.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/fine_tuning/jobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhyperparameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msuffix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjob_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJobCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFineTuningJob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Convergent/productivity24/.venv/lib/python3.12/site-packages/openai/_base_client.py:1213\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1201\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1208\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1210\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1211\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1212\u001b[0m     )\n\u001b[0;32m-> 1213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Convergent/productivity24/.venv/lib/python3.12/site-packages/openai/_base_client.py:902\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    895\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    900\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    901\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Convergent/productivity24/.venv/lib/python3.12/site-packages/openai/_base_client.py:993\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    990\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    992\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 993\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m    996\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    997\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1000\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1001\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'invalid_request_error', 'param': None, 'code': 'exceeded_quota'}}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "file_name = client.files.create(\n",
    "  file=open(\"converted_conversations.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "# print(getattr(file_name, 'id'))\n",
    "\n",
    "create_job = client.fine_tuning.jobs.create(\n",
    "  training_file=getattr(file_name, 'id'),\n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"You're welcome. Have a great day!\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages= [{\"role\": \"system\", \"content\": \"A polite chatbot that deals with e-commerce products.\"}, \n",
    "             {\"role\": \"assistant\", \"content\": \"Thank you for calling BrownBox Customer Support. My name is Tom. How may I assist you today?\"}, \n",
    "             {\"role\": \"user\", \"content\": \"Hi Tom, I'm trying to log in to my account to purchase an Oven Toaster Grill (OTG), but I'm unable to proceed as it's asking for mobile number or email verification. Can you help me with that?\"}, \n",
    "             {\"role\": \"assistant\", \"content\": \"Sure, I can assist you with that. May I know your registered mobile number or email address, please?\"}, \n",
    "             {\"role\": \"user\", \"content\": \"My registered mobile number is +1 123-456-7890.\"}, \n",
    "             {\"role\": \"assistant\", \"content\": \"Thank you. Let me check that for you. I'm sorry to inform you that we don't have this number on our records. Can you please confirm if this is the correct number?\"}, \n",
    "             {\"role\": \"user\", \"content\": \"Oh, I'm sorry. I might have registered with a different number. Can you please check with my email address instead? It's johndoe@email.com.\"}, \n",
    "             {\"role\": \"assistant\", \"content\": \"Sure, let me check that for you. (After a few moments) I see that we have your email address on our records. We'll be sending you a verification code shortly. Please check your email and let me know once you receive it.\"}, \n",
    "             {\"role\": \"user\", \"content\": \"Okay, I received the code. What do I do with it?\"}, \n",
    "             {\"role\": \"assistant\", \"content\": \"Please enter the verification code in the field provided and click on 'Verify'. Once your email address is verified, you'll be able to proceed with your purchase.\"}, \n",
    "             {\"role\": \"user\", \"content\": \"Okay, I entered the code, and it's verified now. Thank you for your help.\"}, \n",
    "             {\"role\": \"assistant\", \"content\": \"You're welcome. Is there anything else I can assist you with?\"}, \n",
    "             {\"role\": \"user\", \"content\": \"No, that's all. Thank you.\"}]\n",
    "\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-t7oOstug37ZUbcb6eKy7RSN9', created_at=1712421372, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9B3P7dz0', finished_at=1712421720, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=8), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-Ke8DBqObuM0u7Zp3BVh771Ph', result_files=['file-1zyBLDrIsP6yabFJ1xTUHY5Y'], status='succeeded', trained_tokens=48550, training_file='file-eiYGcD0x7WZ7v28CxVL0xxGL', validation_file=None, user_provided_suffix=None, seed=1378242904, integrations=[])\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "# Retrieve the state of a fine-tune\n",
    "#retrieve_job = client.fine_tuning.jobs.retrieve(getattr(create_job, 'id'))\n",
    "retrieve_job = client.fine_tuning.jobs.retrieve('ftjob-t7oOstug37ZUbcb6eKy7RSN9')\n",
    "print(retrieve_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Thank you for calling BrownBox customer support. My name is Rachel. How may I assist you today?', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=getattr(retrieve_job, \"fine_tuned_model\"),\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Chat Completion:\n",
    "System Description: You are a helpful assistant.\n",
    "\n",
    "User: Hello!\n",
    "\n",
    "Generated Assistant Response: Thank you for calling BrownBox customer support. My name is Rachel. How may I assist you today?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"I'm sorry to hear that. I'll be happy to help you with that. Can you please provide me with your order number?\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=getattr(retrieve_job, \"fine_tuned_model\"),\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Your name is [your name here].\"},\n",
    "    {\"role\": \"user\", \"content\": \"I have a problem with my toaster. It keeps making weird noses. I want a refund\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Chat Completion:\n",
    "System Description: You are a helpful assistant. Your name is [your name here].\n",
    "\n",
    "User: I have a problem with my toaster. It keeps making weird noses. I want a refund\n",
    "\n",
    "Generated Assistant Response: I'm sorry to hear that. I'll be happy to help you with that. Can you please provide me with your order number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Hi there, I'm sorry to hear that you have been waiting for your order for a long time. Please provide me with your order number so that I can check the status of your order.\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=getattr(retrieve_job, \"fine_tuned_model\"),\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that writes email responses. Your name is [your name here].\"},\n",
    "    {\"role\": \"user\", \"content\": \"I have been waiting for my order for a long time. When will it get here?\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Chat Completion:\n",
    "System Description: You are a helpful assistant that writes email responses. Your name is [your name here].\n",
    "\n",
    "User: I have been waiting for my order for a long time. When will it get here?\n",
    "\n",
    "Generated Assistant Response: Hi there, I'm sorry to hear that you have been waiting for your order for a long time. Please provide me with your order number so that I can check the status of your order."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
